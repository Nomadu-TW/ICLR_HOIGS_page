% \begin{abstract% }
%Reconstructing human-object interaction scenes from monocular videos in the wild remains a significant challenge due to the absence of reliable 3D priors and complex dynamic motions. Existing human-centric reconstruction methods rely heavily on accurate human pose priors and struggle with general dynamic objects, while 4D Gaussian Splatting approaches often fail to capture detailed object motion under occlusion or during long sequences. We present HOIGS, a novel framework that jointly reconstructs humans, dynamic objects, and backgrounds using 3D Gaussians in a unified world space. Our method leverages Score Distillation Sampling (SDS) from a pretrained diffusion model to generate complete 360\textdegree{} 3D shapes at key frames, providing strong geometric priors for initializing dynamic object Gaussians. These priors are temporally propagated using cubic hermite splines, enabling smooth and continuous deformation across time while refining alignment across frames. By combining SMPL-based human modeling, spline-based dynamic object tracking, and Gaussian-based scene representation, HOIGS achieves high-quality reconstruction of complex interaction scenes from monocular inputs. We demonstrate the effectiveness of our approach on challenging real-world sequences, showing substantial improvements over existing baselines in both geometric accuracy and visual fideli% ty.
%\end{abstract}

\begin{abstract}
%인간–객체 상호작용이 포함된 동적 장면을 재구성하는 것은 컴퓨터 비전과 그래픽스 분야의 근본적인 도전 과제이다. 기존 Gaussian Splatting 기반 방법들은 인간 포즈 사전정보에 의존하여 동적 객체를 간과하거나, 모든 움직임을 단일 motion field로 근사하여 복잡한 상호작용을 충분히 포착하지 못한다. 이를 해결하기 위해 본 연구에서는 인간과 객체 간 motion consistency를 명시적으로 학습하는 Human-Object Interaction Gaussian Splatting (HOIGS)를 제안한다. HOIGS는 cross-attention 기반의 HOI 모듈을 통해 사람과 객체의 motion feature 간 상호 의존성을 효과적으로 학습하며, 사람에 대해서는 HexPlane, 객체에 대해서는 Cubic Hermite Spline (CHS)을 deformation baseline으로 적용하여 상호 보완적인 motion feature를 추출한다. 이러한 특징을 통해 HOIGS는 occlusion, contact, manipulation과 같은 복잡한 상호작용 상황에서도 보다 정밀한 deformation 추정을 가능하게 한다. 다양한 데이터셋에서의 실험 결과, 제안한 방법은 기존 human-centric 및 4D Gaussian 접근법을 안정적으로 능가하며, 상호작용 장면의 고품질 재구성을 위한 새로운 가능성을 보여준다.
Reconstructing dynamic scenes with complex human–object interactions is a fundamental challenge in computer vision and graphics. Existing Gaussian Splatting methods either rely on human pose priors, neglecting dynamic objects, or approximate all motions within a single field, limiting their ability to capture interaction-rich dynamics. To address this gap, we propose Human-Object Interaction Gaussian Splatting (HOIGS), which explicitly models interaction-induced deformation between humans and objects through a cross-attention based HOI module. Distinct deformation baselines are employed to extract complementary motion features: hexplane for humans and Cubic Hermite Spline (CHS) for objects. By integrating these heterogeneous features, HOIGS effectively captures interdependent motions and improves deformation estimation in scenarios involving occlusion, contact, and object manipulation. Comprehensive experiments on multiple datasets demonstrate that our method consistently outperforms state-of-the-art human-centric and 4D Gaussian approaches, highlighting the importance of explicitly modeling human–object interactions for high-fidelity reconstruction. The video results of HOIGS are available at: \url{https://anonymous.4open.science/w/HOI-GS/}
\end{abstract}