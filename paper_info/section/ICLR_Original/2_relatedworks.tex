\section{Related Works}

\subsection{Human Modeling}

%Research on modeling realistic human has been actively pursued for a long time. Initially, parametric models were proposed, and based on these, the Human Mesh Reconstruction (HMR) model (\textcolor{blue}{\cite{kanazawa2018end}}) was introduced for estimating human poses from a single image. However, although these models offer computational efficiency, they remain limited in their ability to represent non-body parts such as clothing and accessories. To overcome this limitation, implicit function-based methods (\textcolor{blue}{\cite{huang2020arch, saito2019pifu, saito2020pifuhd, xiu2022icon, xiu2023econ}}) were proposed. While this line of work is capable of capturing fine details such as clothing and hair, it remains limited in ensuring global consistency and achieving efficient rendering performance. These methods place their primary focus on reconstructing human geometry, with limited consideration of HOI aspects. With the emergence of Neural Radiance Fields(NeRF) (\textcolor{blue}{\cite{mildenhall2021nerf}}), several approaches (\textcolor{blue}{\cite{peng2021neural, jiang2022neuman, weng2022humannerf, alldieck2022photorealistic, liao2023high, guo2023vid2avatar}}) applying NeRF to human body modeling were introduced. Despite their strengths in view consistency and realistic appearance modeling, NeRF-based methods remain limited by high computational training costs and inefficient rendering performance. In terms of HOI, certain work (\textcolor{blue}{\cite{fan2024hold}}) attempted to incorporate objects into the scene. Nevertheless, the treatment of objects was still constrained, as their dynamic properties and more general forms of human–object interaction were not fully captured. Recently, a new 3D representation method called 3D Gaussian Splatting (3DGS) (\textcolor{blue}{\cite{kerbl20233d}}) was proposed. There have also been attempts to apply it to 3D human reconstruction (\textcolor{blue}{\cite{kocabas2024hugs, moon2024expressive, hu2024gauhuman,  liu2024animatable, hu2024gaussianavatar}}).
%In these works. they primarily focused on animatable and efficient representations of the human body, while objects appearing in the scene were still regarded as static and non-interactive. To address this issue, a method that leverages cross-interaction between human and objects in dynamic HOI scenes is required. Therefore, we propose the HOIGS model which achieves stable human reconstruction in dynamic scenes and effectively models HOI.
Research on realistic human modeling has long been pursued. Early parametric models enabled efficient estimation of human pose, exemplified by HMR (\textcolor{blue}{\cite{kanazawa2018end}}), but struggled to capture clothing and accessories. To address this, implicit function-based methods (\textcolor{blue}{\cite{huang2020arch, saito2019pifu, saito2020pifuhd, xiu2022icon, xiu2023econ}}) were proposed, which recover fine details such as hair and clothing but remain limited in global consistency and rendering efficiency. These methods mainly focused on human geometry with little attention to human-object interactions.
With Neural Radiance Fields (NeRF) (\textcolor{blue}{\cite{mildenhall2021nerf}}), several works applied it to human modeling (\textcolor{blue}{\cite{peng2021neural, jiang2022neuman, weng2022humannerf, alldieck2022photorealistic, liao2023high, guo2023vid2avatar}}), achieving realistic appearance and view consistency but still suffering from high training cost and slow rendering. In terms of human-object interactions, some attempts (\textcolor{blue}{\cite{fan2024hold}}) introduced objects, yet dynamic interactions were not fully captured.
Recently, 3D Gaussian Splatting (3DGS) (\textcolor{blue}{\cite{kerbl20233d}}) emerged as a new representation and has been applied to human reconstruction (\textcolor{blue}{\cite{kocabas2024hugs, moon2024expressive, hu2024gauhuman, liu2024animatable, hu2024gaussianavatar}}). However, most efforts still regard objects as static. To overcome this, we propose HOIGS, a model for stable human reconstruction in dynamic scenes that explicitly captures human–object interactions.


\subsection{Dynamic Scene Modeling}
The field of dynamic scene rendering and reconstruction has seen a paradigm shift from initial NeRF-based methods  (\textcolor{blue}{\cite{park2021nerfies, park2021hypernerf, wu2022d, fridovich2023k}}) to the more recent 3D Gaussian Splatting framework. Previous studies such as HOSNeRF (\textcolor{blue}{\cite{liu2023hosnerf}}) effectively modeled human-object interactions by controlling human motion through skeleton-based models such as SMPL and leveraging object state embeddings. Nevertheless, the implicit representation inherent to NeRF led to significant computational overhead in training and rendering, and limited the ability to represent detailed features in large-scale environments. To address this efficiency bottleneck, a line of work has emerged that extends 3DGS to the temporal domain, known as 4D Gaussian Splatting (4DGS) (\textcolor{blue}{\cite{wu20244d, yang2023real}}). Although these methods achieve real-time rendering speeds, they face persistent issues. Most 4DGS approaches rely on Structure-from-Motion for Gaussian initialization, which is fundamentally ill-suited for dynamic subjects as it operates on the assumption of a static world. This leads to inaccurate point cloud generation for moving objects. Moreover, the MLP-based implicit deformation fields used to capture motion, while adequate for simple trajectories, often result in over-smoothed or unnatural movements when applied to complex, in-the-wild scenarios. Therefore, we propose an explicit, spline-based motion model. This approach allows us to model intricate temporal movements with high fidelity, achieving high-quality rendering even in dynamic scenes that include complex human-object interactions.
